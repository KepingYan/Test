{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_nyctaxi.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1zvWvMhBNUolMOVMfzYqepXB671v2KcPk","authorship_tag":"ABX9TyMf/CAj2GPmhDInrjlGKh3X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **How RayDP works together with Pytorch**"],"metadata":{"id":"2TxtrYkpljYO"}},{"cell_type":"markdown","source":["RayDP is a distributed data processing library that provides simple APIs for running Spark on Ray and integrating Spark with distributed deep learning and machine learning frameworks. This document builds an end-to-end deep learning pipeline on a single Ray cluster by using Spark for data preprocessing, and uses distributed estimator based on the raydp api to complete the training and evaluation."],"metadata":{"id":"PVGNVwUU9lGW"}},{"cell_type":"markdown","source":["## 1. Colab enviroment Setup"],"metadata":{"id":"JJCwQHcvlmqF"}},{"cell_type":"markdown","source":["RayDP requires Ray and PySpark. At the same time, pytorch is used to build deep learning model."],"metadata":{"id":"iMRuDWw9qh29"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"SQplP7vYlCp2","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1652762626241,"user_tz":-480,"elapsed":140802,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"63f34175-363b-4eda-d552-1ce87a17aa9a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ray==1.9\n","  Downloading ray-1.9.0-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n","\u001b[K     |████████████████████████████████| 57.6 MB 1.6 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (3.17.3)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (4.3.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (1.21.6)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (1.44.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (3.13)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 44.0 MB/s \n","\u001b[?25hRequirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (21.4.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (1.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (3.6.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray==1.9) (7.1.2)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray==1.9) (1.15.0)\n","Collecting deprecated>=1.2.3\n","  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray==1.9) (21.3)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray==1.9) (4.11.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray==1.9) (4.2.0)\n","Collecting async-timeout>=4.0.2\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray==1.9) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray==1.9) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray==1.9) (3.0.8)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray==1.9) (5.7.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray==1.9) (0.18.1)\n","Installing collected packages: deprecated, async-timeout, redis, ray\n","Successfully installed async-timeout-4.0.2 deprecated-1.2.13 ray-1.9.0 redis-4.3.1\n","Collecting raydp\n","  Downloading raydp-0.4.2-py3-none-any.whl (10.5 MB)\n","\u001b[K     |████████████████████████████████| 10.5 MB 4.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from raydp) (1.21.6)\n","Collecting netifaces\n","  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from raydp) (5.4.8)\n","Requirement already satisfied: ray[default]>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from raydp) (1.9.0)\n","Requirement already satisfied: pyarrow>=0.10 in /usr/local/lib/python3.7/dist-packages (from raydp) (6.0.1)\n","Collecting pyspark>=3.2.0\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 33 kB/s \n","\u001b[?25hCollecting typing\n","  Downloading typing-3.7.4.3.tar.gz (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 7.5 MB/s \n","\u001b[?25hCollecting aiohttp==3.7.4\n","  Downloading aiohttp-3.7.4-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 43.9 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from raydp) (1.3.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->raydp) (21.4.0)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 49.3 MB/s \n","\u001b[?25hCollecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 1.9 MB/s \n","\u001b[?25hCollecting async-timeout<4.0,>=3.0\n","  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n","Requirement already satisfied: chardet<4.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->raydp) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.7.4->raydp) (4.2.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->raydp) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->raydp) (2022.1)\n","Collecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 50.3 MB/s \n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->raydp) (1.15.0)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (1.44.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (3.6.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (4.3.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (3.13)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (1.0.3)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (4.3.1)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (3.17.3)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (7.1.2)\n","Collecting aiosignal\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting gpustat>=1.0.0b1\n","  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 257 kB/s \n","\u001b[?25hCollecting opencensus\n","  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\n","\u001b[K     |████████████████████████████████| 128 kB 36.8 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (2.23.0)\n","Collecting frozenlist\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 49.6 MB/s \n","\u001b[?25hCollecting aiohttp-cors\n","  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n","Collecting aioredis<2\n","  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n","\u001b[K     |████████████████████████████████| 65 kB 3.7 MB/s \n","\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (0.14.1)\n","Collecting colorful\n","  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n","\u001b[K     |████████████████████████████████| 201 kB 39.1 MB/s \n","\u001b[?25hCollecting py-spy>=0.2.0\n","  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n","\u001b[K     |████████████████████████████████| 3.1 MB 22.9 MB/s \n","\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]>=1.8.0->raydp) (6.0.0)\n","Collecting hiredis\n","  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n","\u001b[K     |████████████████████████████████| 85 kB 4.0 MB/s \n","\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]>=1.8.0->raydp) (7.352.0)\n","Collecting blessed>=1.17.1\n","  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]>=1.8.0->raydp) (0.2.5)\n","Collecting redis>=3.5.0\n","  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 50.7 MB/s \n","\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n","\u001b[K     |████████████████████████████████| 226 kB 52.7 MB/s \n","\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 42.4 MB/s \n","\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n","\u001b[K     |████████████████████████████████| 225 kB 54.1 MB/s \n","\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n","\u001b[K     |████████████████████████████████| 175 kB 47.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]>=1.8.0->raydp) (4.11.3)\n","Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]>=1.8.0->raydp) (1.2.13)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]>=1.8.0->raydp) (21.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]>=1.8.0->raydp) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]>=1.8.0->raydp) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[default]>=1.8.0->raydp) (3.0.8)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.7.4->raydp) (2.10)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]>=1.8.0->raydp) (5.7.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]>=1.8.0->raydp) (0.18.1)\n","Collecting opencensus-context>=0.1.2\n","  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]>=1.8.0->raydp) (1.31.5)\n","Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (1.35.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (1.56.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (4.2.4)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]>=1.8.0->raydp) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]>=1.8.0->raydp) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]>=1.8.0->raydp) (1.24.3)\n","Building wheels for collected packages: pyspark, gpustat, typing\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=94c343921c946912e7bf476e429903ceebb6238571a162d8406cbbef41e9827f\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=b4a97d1fc4426e58ccfd54a0dd32892627da2a27008307a680faf9119aef9b06\n","  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n","  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26325 sha256=037f5fb9791f3de171ed153310ba8c33e800627843afd61097c25c85746964dd\n","  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n","Successfully built pyspark gpustat typing\n","Installing collected packages: multidict, yarl, async-timeout, redis, opencensus-context, hiredis, frozenlist, blessed, aiohttp, py4j, py-spy, opencensus, gpustat, colorful, aiosignal, aioredis, aiohttp-cors, typing, pyspark, netifaces, raydp\n","  Attempting uninstall: async-timeout\n","    Found existing installation: async-timeout 4.0.2\n","    Uninstalling async-timeout-4.0.2:\n","      Successfully uninstalled async-timeout-4.0.2\n","  Attempting uninstall: redis\n","    Found existing installation: redis 4.3.1\n","    Uninstalling redis-4.3.1:\n","      Successfully uninstalled redis-4.3.1\n","Successfully installed aiohttp-3.7.4 aiohttp-cors-0.7.0 aioredis-1.3.1 aiosignal-1.2.0 async-timeout-3.0.1 blessed-1.19.1 colorful-0.5.4 frozenlist-1.3.0 gpustat-1.0.0b1 hiredis-2.0.0 multidict-6.0.2 netifaces-0.11.0 opencensus-0.9.0 opencensus-context-0.1.2 py-spy-0.3.12 py4j-0.10.9.3 pyspark-3.2.1 raydp-0.4.2 redis-4.1.4 typing-3.7.4.3 yarl-1.7.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["typing"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (1.9.0)\n","Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.4)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.13)\n","Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.44.0)\n","Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.17.3)\n","Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (21.4.0)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.6.0)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.3)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.6)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.9)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n","Collecting tensorboardX>=1.9\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 4.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n","Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.28.1->ray[tune]) (1.15.0)\n","Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (21.3)\n","Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (4.11.3)\n","Requirement already satisfied: deprecated>=1.2.3 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[tune]) (1.2.13)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[tune]) (1.14.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (3.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[tune]) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.4->redis>=3.5.0->ray[tune]) (3.0.8)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.18.1)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2022.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.8.1+cpu\n","  Downloading https://download.pytorch.org/whl/cpu/torch-1.8.1%2Bcpu-cp37-cp37m-linux_x86_64.whl (169.1 MB)\n","\u001b[K     |████████████████████████████████| 169.1 MB 77 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cpu) (4.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cpu) (1.21.6)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.8.1+cpu which is incompatible.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.1+cpu which is incompatible.\n","torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.1+cpu which is incompatible.\u001b[0m\n","Successfully installed torch-1.8.1+cpu\n"]}],"source":["! pip install ray==1.9\n","! pip install raydp\n","! pip install ray[tune]\n","! pip install torch==1.8.1+cpu -f https://download.pytorch.org/whl/torch_stable.html"]},{"cell_type":"markdown","source":["## 2. Get the data file"],"metadata":{"id":"XWw2fBhfqvME"}},{"cell_type":"markdown","source":["The dataset is from: https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset, and we store the file in github repository. It's used to predict whether a patient is likely to get stroke based on the input parameters like gender, age, various diseases, and smoking status. Each row in the data provides relavant information about the patient. "],"metadata":{"id":"pFZtArpXqyS2"}},{"cell_type":"code","source":["! wget https://raw.githubusercontent.com/KepingYan/Test/main/data/healthcare-dataset-stroke-data.csv -O healthcare-dataset-stroke-data.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-Hzp_q7qzz5","executionInfo":{"status":"ok","timestamp":1652762627771,"user_tz":-480,"elapsed":1551,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"8bb77342-d4c7-4c5b-a841-751154434f33"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-17 04:43:45--  https://raw.githubusercontent.com/KepingYan/Test/main/data/healthcare-dataset-stroke-data.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 316971 (310K) [text/plain]\n","Saving to: ‘healthcare-dataset-stroke-data.csv’\n","\n","healthcare-dataset- 100%[===================>] 309.54K  --.-KB/s    in 0.04s   \n","\n","2022-05-17 04:43:47 (7.73 MB/s) - ‘healthcare-dataset-stroke-data.csv’ saved [316971/316971]\n","\n"]}]},{"cell_type":"markdown","source":["## 3. Init or connect to a ray cluster"],"metadata":{"id":"Y-ceLv2-q__G"}},{"cell_type":"code","source":["import ray\n","\n","ray.init(num_cpus=6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CVFQcpiJrC8Y","executionInfo":{"status":"ok","timestamp":1652762634882,"user_tz":-480,"elapsed":7113,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"9e0a6253-3255-44a9-c19f-87019ce8cded"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-17 04:43:51,684\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'metrics_export_port': 54253,\n"," 'node_id': '1e0e1bce883f672ebace868dbf36e508b0bd0a203cabd13d5e28f922',\n"," 'node_ip_address': '172.28.0.2',\n"," 'object_store_address': '/tmp/ray/session_2022-05-17_04-43-47_883416_61/sockets/plasma_store',\n"," 'raylet_ip_address': '172.28.0.2',\n"," 'raylet_socket_name': '/tmp/ray/session_2022-05-17_04-43-47_883416_61/sockets/raylet',\n"," 'redis_address': '172.28.0.2:6379',\n"," 'session_dir': '/tmp/ray/session_2022-05-17_04-43-47_883416_61',\n"," 'webui_url': '127.0.0.1:8265'}"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## 4. Get a spark session"],"metadata":{"id":"MvuatpSsrGHD"}},{"cell_type":"code","source":["import raydp\n","\n","app_name = \"Stoke Prediction with RayDP\"\n","num_executors = 1\n","cores_per_executor = 1\n","memory_per_executor = \"500M\"\n","spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)"],"metadata":{"id":"ze-waQ7zrH79","executionInfo":{"status":"ok","timestamp":1652762659259,"user_tz":-480,"elapsed":24380,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 5. Get data from .csv file via 'spark' created by **raydp**"],"metadata":{"id":"AYdTc0wQrMSQ"}},{"cell_type":"code","source":["data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n","        .option(\"inferSchema\", \"true\") \\\n","        .load(\"/content/healthcare-dataset-stroke-data.csv\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vVAO9gwrNY9","executionInfo":{"status":"ok","timestamp":1652762678301,"user_tz":-480,"elapsed":19047,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"8dd90f27-8ec6-435a-9725-2dce755debfe"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n"]}]},{"cell_type":"markdown","source":["## 6. Define the data_process function"],"metadata":{"id":"n8UO4brnrP_V"}},{"cell_type":"markdown","source":["The dataset is converted to `pyspark.sql.dataframe.DataFrame`. Before feeding into the deep learning model, we can use raydp to do some transformation operations on dataset."],"metadata":{"id":"T1TJVdSCrSfg"}},{"cell_type":"markdown","source":["### 6.1 Data Analysis"],"metadata":{"id":"xwC6GDVrrU0s"}},{"cell_type":"markdown","source":["Here is a part of the data analysis."],"metadata":{"id":"K_VMeCUDrZOd"}},{"cell_type":"code","source":["# Data overview\n","data.show(5)\n","# Statistical N/A distribution\n","# There are 201 'N/A' value in column 'bmi column',\n","# we can update them the mean of the column\n","data.describe().show()\n","data.filter(data.bmi=='N/A').count()\n","# Observe the distribution of the column 'gender'\n","# Then we should remove the outliers 'Other'\n","data.rollup(data.gender).count().show()\n","# Observe the proportion of positive and negative samples.\n","data.rollup(data.stroke).count().show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjF-QfKsrXTF","executionInfo":{"status":"ok","timestamp":1652762690449,"user_tz":-480,"elapsed":12163,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"ceec027b-830a-44fe-9659-5073b3bdbbd9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n","|   id|gender| age|hypertension|heart_disease|ever_married|    work_type|Residence_type|avg_glucose_level| bmi| smoking_status|stroke|\n","+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n","| 9046|  Male|67.0|           0|            1|         Yes|      Private|         Urban|           228.69|36.6|formerly smoked|     1|\n","|51676|Female|61.0|           0|            0|         Yes|Self-employed|         Rural|           202.21| N/A|   never smoked|     1|\n","|31112|  Male|80.0|           0|            1|         Yes|      Private|         Rural|           105.92|32.5|   never smoked|     1|\n","|60182|Female|49.0|           0|            0|         Yes|      Private|         Urban|           171.23|34.4|         smokes|     1|\n","| 1665|Female|79.0|           1|            0|         Yes|Self-employed|         Rural|           174.12|  24|   never smoked|     1|\n","+-----+------+----+------------+-------------+------------+-------------+--------------+-----------------+----+---------------+------+\n","only showing top 5 rows\n","\n","+-------+-----------------+------+------------------+------------------+-------------------+------------+---------+--------------+------------------+------------------+--------------+-------------------+\n","|summary|               id|gender|               age|      hypertension|      heart_disease|ever_married|work_type|Residence_type| avg_glucose_level|               bmi|smoking_status|             stroke|\n","+-------+-----------------+------+------------------+------------------+-------------------+------------+---------+--------------+------------------+------------------+--------------+-------------------+\n","|  count|             5110|  5110|              5110|              5110|               5110|        5110|     5110|          5110|              5110|              5110|          5110|               5110|\n","|   mean|36517.82935420744|  null|43.226614481409015|0.0974559686888454|0.05401174168297456|        null|     null|          null|106.14767710371804|28.893236911794673|          null| 0.0487279843444227|\n","| stddev|21161.72162482715|  null| 22.61264672311348| 0.296606674233791|0.22606298750336554|        null|     null|          null| 45.28356015058193|  7.85406672968016|          null|0.21531985698023753|\n","|    min|               67|Female|              0.08|                 0|                  0|          No| Govt_job|         Rural|             55.12|              10.3|       Unknown|                  0|\n","|    max|            72940| Other|              82.0|                 1|                  1|         Yes| children|         Urban|            271.74|               N/A|        smokes|                  1|\n","+-------+-----------------+------+------------------+------------------+-------------------+------------+---------+--------------+------------------+------------------+--------------+-------------------+\n","\n","+------+-----+\n","|gender|count|\n","+------+-----+\n","|  Male| 2115|\n","|  null| 5110|\n","|Female| 2994|\n","| Other|    1|\n","+------+-----+\n","\n","+------+-----+\n","|stroke|count|\n","+------+-----+\n","|     1|  249|\n","|     0| 4861|\n","|  null| 5110|\n","+------+-----+\n","\n"]}]},{"cell_type":"markdown","source":["### 6.2 Define operations"],"metadata":{"id":"BwQIFmPArb4t"}},{"cell_type":"markdown","source":["Define data processing operations based on data analysis results."],"metadata":{"id":"nWQp7YiJsYU2"}},{"cell_type":"code","source":["from pyspark.sql.functions import hour, quarter, month, year, dayofweek, dayofmonth, weekofyear, col, lit, udf, abs as functions_abs, avg"],"metadata":{"id":"pYZLIkqwrduU","executionInfo":{"status":"ok","timestamp":1652762690450,"user_tz":-480,"elapsed":16,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Delete the useless column 'id'\n","def drop_col(data):\n","    data = data.drop('id')\n","    return data"],"metadata":{"id":"YqnWEwlMrkJ3","executionInfo":{"status":"ok","timestamp":1652762690450,"user_tz":-480,"elapsed":15,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Replace the value N/A in 'bmi'\n","def replace_nan(data):\n","    bmi_avg = data.agg(avg(col(\"bmi\"))).head()[0]\n","\n","    @udf(\"float\")\n","    def replace_nan(value):\n","        if value=='N/A':\n","            return float(bmi_avg)\n","        else:\n","            return float(value)\n","\n","    # Replace the value N/A\n","    data = data.withColumn('bmi', replace_nan(col(\"bmi\")))\n","    return data"],"metadata":{"id":"x4FGXwNxrlK_","executionInfo":{"status":"ok","timestamp":1652762690451,"user_tz":-480,"elapsed":15,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Drop the only one value 'Other' in column 'gender'\n","def clean_value(data):\n","    data = data.filter(data.gender != 'Other')\n","    return data"],"metadata":{"id":"JSAv6q_3rnmn","executionInfo":{"status":"ok","timestamp":1652762690451,"user_tz":-480,"elapsed":15,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Transform the category columns\n","def trans_category(data):\n","    @udf(\"int\")\n","    def trans_gender(value):\n","        gender = {'Female': 0,\n","                  'Male': 1}\n","        return int(gender[value])\n","\n","    @udf(\"int\")\n","    def trans_ever_married(value):\n","        residence_type = {'No': 0,\n","                          'Yes': 1}\n","        return int(residence_type[value])\n","\n","    @udf(\"int\")\n","    def trans_work_type(value):\n","        work_type = {'children': 0,\n","                     'Govt_job': 1,\n","                     'Never_worked': 2,\n","                     'Private': 3,\n","                     'Self-employed': 4}\n","        return int(work_type[value])\n","\n","    @udf(\"int\")\n","    def trans_residence_type(value):\n","        residence_type = {'Rural': 0,\n","                          'Urban': 1}\n","        return int(residence_type[value])\n","\n","    @udf(\"int\")\n","    def trans_smoking_status(value):\n","        smoking_status = {'formerly smoked': 0,\n","                          'never smoked': 1,\n","                          'smokes': 2,\n","                          'Unknown': 3}\n","        return int(smoking_status[value])\n","\n","    data = data.withColumn('gender', trans_gender(col('gender'))) \\\n","               .withColumn('ever_married', trans_ever_married(col('ever_married'))) \\\n","               .withColumn('work_type', trans_work_type(col('work_type'))) \\\n","               .withColumn('Residence_type', trans_residence_type(col('Residence_type'))) \\\n","               .withColumn('smoking_status', trans_smoking_status(col('smoking_status')))\n","    return data"],"metadata":{"id":"24PMi6OHrpDy","executionInfo":{"status":"ok","timestamp":1652762690452,"user_tz":-480,"elapsed":15,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Add the discretized column of 'Age'\n","def map_age(data):\n","    @udf(\"int\")\n","    def get_value(value):\n","        if value >= 18 and value < 26:\n","            return int(0)\n","        elif value >=26 and value < 36:\n","            return int(1)\n","        elif value >=36 and value < 46:\n","            return int(2)\n","        elif value >=46 and value < 56:\n","            return int(3)\n","        else:\n","            return int(4)\n","\n","    data = data.withColumn('age_dis', get_value(col('age')))\n","    return data"],"metadata":{"id":"_V3UsmQwrq3I","executionInfo":{"status":"ok","timestamp":1652762690453,"user_tz":-480,"elapsed":16,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Preprocess the data\n","def data_preprocess(data):\n","    data = drop_col(data)\n","    data = replace_nan(data)\n","    data = clean_value(data)\n","    data = trans_category(data)\n","    data = map_age(data)\n","    return data"],"metadata":{"id":"-X0yYDz1rsnA","executionInfo":{"status":"ok","timestamp":1652762690453,"user_tz":-480,"elapsed":15,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## 7. Data processing"],"metadata":{"id":"dfgFQdRRruS5"}},{"cell_type":"code","source":["import torch\n","from raydp.utils import random_split\n","\n","# Transform the dataset\n","data = data_preprocess(data)\n","# Split data into train_dataset and test_dataset\n","train_df, test_df = random_split(data, [0.8, 0.2], 0)\n","# Balance the positive and negative samples\n","train_df_neg = train_df.filter(train_df.stroke == '1')\n","train_df = train_df.unionByName(train_df_neg)\n","train_df = train_df.unionByName(train_df_neg)\n","features = [field.name for field in list(train_df.schema) if field.name != \"stroke\"]\n","# Convert spark dataframe into ray Dataset\n","# Remember to align ``parallelism`` with ``num_workers`` of ray train\n","train_dataset = ray.data.from_spark(train_df, parallelism = 8)\n","test_dataset = ray.data.from_spark(test_df, parallelism = 8)\n","feature_dtype = [torch.float] * len(features)"],"metadata":{"id":"vrudeEb1ryy2","executionInfo":{"status":"ok","timestamp":1652762705184,"user_tz":-480,"elapsed":14746,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["## 8. Define a neural network model"],"metadata":{"id":"B42j2xAfr3Wi"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class NET_Model(nn.Module):\n","    def __init__(self, cols):\n","        super().__init__()\n","        self.emb_layer_gender = nn.Embedding(2, 1)           # gender\n","        self.emb_layer_hypertension = nn.Embedding(2,1)      # hypertension\n","        self.emb_layer_heart_disease = nn.Embedding(2,1)     # heart_disease\n","        self.emb_layer_ever_married = nn.Embedding(2, 1)     # ever_married\n","        self.emb_layer_work = nn.Embedding(5, 1)             # work_type\n","        self.emb_layer_residence = nn.Embedding(2, 1)        # Residence_type\n","        self.emb_layer_smoking_status = nn.Embedding(4, 1)   # smoking_status\n","        self.emb_layer_age = nn.Embedding(5, 1)              # age column after discretization\n","        self.fc1 = nn.Linear(cols, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 16)\n","        self.fc5 = nn.Linear(16, 2)\n","        self.bn1 = nn.BatchNorm1d(256)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.bn4 = nn.BatchNorm1d(16)\n","\n","    def forward(self, *x):\n","        x = torch.cat(x, dim=1)\n","        # pick the dense attribute columns\n","        dense_columns = x[:, [1,7,8]]\n","        # Embedding operation on sparse attribute columns\n","        sparse_col_1 = self.emb_layer_gender(x[:, 0].long())\n","        sparse_col_2 = self.emb_layer_hypertension(x[:, 2].long())\n","        sparse_col_3 = self.emb_layer_heart_disease(x[:, 3].long())\n","        sparse_col_4 = self.emb_layer_ever_married(x[:, 4].long())\n","        sparse_col_5 = self.emb_layer_work(x[:, 5].long())\n","        sparse_col_6 = self.emb_layer_residence(x[:, 6].long())\n","        sparse_col_7 = self.emb_layer_smoking_status(x[:, 9].long())\n","        sparse_col_8 = self.emb_layer_age(x[:, 10].long())\n","        # Splice sparse attribute columns and dense attribute columns\n","        x = torch.cat([dense_columns, sparse_col_1, sparse_col_2, sparse_col_3, sparse_col_4, sparse_col_5, sparse_col_6, sparse_col_7, sparse_col_8], dim=1)\n","\n","        x = F.relu(self.fc1(x))\n","        x = self.bn1(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.bn2(x)\n","        x = F.relu(self.fc3(x))\n","        x = self.bn3(x)\n","        x = F.relu(self.fc4(x))\n","        x = self.bn4(x)\n","        x = self.fc5(x)\n","        return x\n"],"metadata":{"id":"Zd69EFv9r58U","executionInfo":{"status":"ok","timestamp":1652762705184,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## 9. Create model, critetion and optimizer"],"metadata":{"id":"Z85SeUPNmdXj"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","net_model = NET_Model(len(features))\n","criterion = nn.SmoothL1Loss()\n","optimizer = torch.optim.Adam(net_model.parameters(), lr=0.001)"],"metadata":{"id":"BM1BOwrgmjzN","executionInfo":{"status":"ok","timestamp":1652762705184,"user_tz":-480,"elapsed":4,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## 10. Create distributed estimator and train"],"metadata":{"id":"_csycx41mpuj"}},{"cell_type":"code","source":["from raydp.torch import TorchEstimator\n","\n","estimator = TorchEstimator(num_workers=1, model=net_model, optimizer=optimizer, loss=criterion,\n","                           feature_columns=features, label_column=\"stroke\", batch_size=64,\n","                           num_epochs=30)\n","# Train the model\n","estimator.fit_on_spark(train_df, test_df)\n","estimator.shutdown()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"heY9ullomyzh","executionInfo":{"status":"ok","timestamp":1652762747187,"user_tz":-480,"elapsed":42007,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"ec3e7da1-3431-4f27-9b5e-946fb98e0b29"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(TorchRunner pid=1080)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","\u001b[2m\u001b[36m(TorchRunner pid=1080)\u001b[0m   return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch-0: {'num_samples': 4454, 'epoch': 1.0, 'batch_count': 70.0, 'train_loss': 0.07485512316855926, 'last_train_loss': 0.0520394966006279}\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(TorchRunner pid=1080)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([38, 1])) that is different to the input size (torch.Size([38, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","\u001b[2m\u001b[36m(TorchRunner pid=1080)\u001b[0m   return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch-1: {'num_samples': 4454, 'epoch': 2.0, 'batch_count': 70.0, 'train_loss': 0.05209015807965758, 'last_train_loss': 0.06677234917879105}\n","Epoch-2: {'num_samples': 4454, 'epoch': 3.0, 'batch_count': 70.0, 'train_loss': 0.048088046336955535, 'last_train_loss': 0.0547766387462616}\n","Epoch-3: {'num_samples': 4454, 'epoch': 4.0, 'batch_count': 70.0, 'train_loss': 0.048267952291538324, 'last_train_loss': 0.07120266556739807}\n","Epoch-4: {'num_samples': 4454, 'epoch': 5.0, 'batch_count': 70.0, 'train_loss': 0.04843106401016159, 'last_train_loss': 0.036428745836019516}\n","Epoch-5: {'num_samples': 4454, 'epoch': 6.0, 'batch_count': 70.0, 'train_loss': 0.04771103299769469, 'last_train_loss': 0.026480354368686676}\n","Epoch-6: {'num_samples': 4454, 'epoch': 7.0, 'batch_count': 70.0, 'train_loss': 0.047705781934209934, 'last_train_loss': 0.07878496497869492}\n","Epoch-7: {'num_samples': 4454, 'epoch': 8.0, 'batch_count': 70.0, 'train_loss': 0.04731543994620342, 'last_train_loss': 0.035199981182813644}\n"]},{"output_type":"stream","name":"stderr","text":["2022-05-17 04:45:20,672\tWARNING worker.py:1245 -- (ip=172.28.0.2) The agent on node 736c7e8b2e70 failed to be restarted 5 times. There are 3 possible problems if you see this error.\n","  1. The dashboard might not display correct information on this node.\n","  2. Metrics on this node won't be reported.\n","  3. runtime_env APIs won't work.\n","Check out the `dashboard_agent.log` to see the detailed failure messages.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch-8: {'num_samples': 4454, 'epoch': 9.0, 'batch_count': 70.0, 'train_loss': 0.04675104429248635, 'last_train_loss': 0.0598708838224411}\n","Epoch-9: {'num_samples': 4454, 'epoch': 10.0, 'batch_count': 70.0, 'train_loss': 0.04691653900002357, 'last_train_loss': 0.028144823387265205}\n","Epoch-10: {'num_samples': 4454, 'epoch': 11.0, 'batch_count': 70.0, 'train_loss': 0.04727107569488325, 'last_train_loss': 0.06265528500080109}\n","Epoch-11: {'num_samples': 4454, 'epoch': 12.0, 'batch_count': 70.0, 'train_loss': 0.04663434016614898, 'last_train_loss': 0.03826573118567467}\n","Epoch-12: {'num_samples': 4454, 'epoch': 13.0, 'batch_count': 70.0, 'train_loss': 0.046925004998236215, 'last_train_loss': 0.04130573570728302}\n","Epoch-13: {'num_samples': 4454, 'epoch': 14.0, 'batch_count': 70.0, 'train_loss': 0.04591377142550809, 'last_train_loss': 0.0486239455640316}\n","Epoch-14: {'num_samples': 4454, 'epoch': 15.0, 'batch_count': 70.0, 'train_loss': 0.04579158623622949, 'last_train_loss': 0.040485624223947525}\n","Epoch-15: {'num_samples': 4454, 'epoch': 16.0, 'batch_count': 70.0, 'train_loss': 0.04556101041862287, 'last_train_loss': 0.06069893017411232}\n","Epoch-16: {'num_samples': 4454, 'epoch': 17.0, 'batch_count': 70.0, 'train_loss': 0.045758867809456136, 'last_train_loss': 0.036031488329172134}\n","Epoch-17: {'num_samples': 4454, 'epoch': 18.0, 'batch_count': 70.0, 'train_loss': 0.04571766828592042, 'last_train_loss': 0.030466808006167412}\n","Epoch-18: {'num_samples': 4454, 'epoch': 19.0, 'batch_count': 70.0, 'train_loss': 0.045839728564224705, 'last_train_loss': 0.0341600626707077}\n","Epoch-19: {'num_samples': 4454, 'epoch': 20.0, 'batch_count': 70.0, 'train_loss': 0.04551123481764085, 'last_train_loss': 0.031770773231983185}\n","Epoch-20: {'num_samples': 4454, 'epoch': 21.0, 'batch_count': 70.0, 'train_loss': 0.04525735694455041, 'last_train_loss': 0.061011213809251785}\n","Epoch-21: {'num_samples': 4454, 'epoch': 22.0, 'batch_count': 70.0, 'train_loss': 0.04578355347154705, 'last_train_loss': 0.09957220405340195}\n","Epoch-22: {'num_samples': 4454, 'epoch': 23.0, 'batch_count': 70.0, 'train_loss': 0.04602151040906161, 'last_train_loss': 0.029922939836978912}\n","Epoch-23: {'num_samples': 4454, 'epoch': 24.0, 'batch_count': 70.0, 'train_loss': 0.04553373448875221, 'last_train_loss': 0.06053571775555611}\n","Epoch-24: {'num_samples': 4454, 'epoch': 25.0, 'batch_count': 70.0, 'train_loss': 0.04494632821116926, 'last_train_loss': 0.02997615747153759}\n","Epoch-25: {'num_samples': 4454, 'epoch': 26.0, 'batch_count': 70.0, 'train_loss': 0.045606867557865756, 'last_train_loss': 0.030746322125196457}\n","Epoch-26: {'num_samples': 4454, 'epoch': 27.0, 'batch_count': 70.0, 'train_loss': 0.04552589302701055, 'last_train_loss': 0.0647154450416565}\n","Epoch-27: {'num_samples': 4454, 'epoch': 28.0, 'batch_count': 70.0, 'train_loss': 0.04444508745155636, 'last_train_loss': 0.034711193293333054}\n","Epoch-28: {'num_samples': 4454, 'epoch': 29.0, 'batch_count': 70.0, 'train_loss': 0.0452804122058249, 'last_train_loss': 0.04716550186276436}\n","Epoch-29: {'num_samples': 4454, 'epoch': 30.0, 'batch_count': 70.0, 'train_loss': 0.044956601948737025, 'last_train_loss': 0.03448208421468735}\n","{'num_samples': 1053, 'batch_count': 17.0, 'val_loss': 0.03087900246777426, 'last_val_loss': 0.02766617015004158, 'val_accuracy': 26.885090218423553, 'last_val_accuracy': 12.344827586206897}\n"]}]},{"cell_type":"markdown","source":["## 11. shut down ray and raydp"],"metadata":{"id":"nHRY731sm4nR"}},{"cell_type":"code","source":["raydp.stop_spark()\n","ray.shutdown()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dMt8Om94m9iH","executionInfo":{"status":"ok","timestamp":1652762750507,"user_tz":-480,"elapsed":3327,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"66616dba-93c4-4236-d98e-53a082b94ba4"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-17 04:45:46,494\tWARNING worker.py:1245 -- A worker died or was killed while executing a task by an unexpected system error. To troubleshoot the problem, check the logs for the dead worker. RayTask ID: ffffffffffffffff6d207b7300571ec7b33ae73701000000 Worker ID: dea6418a85b772a8ca9487f0abf31ca80adfb0c2f8d18fad26a81518 Node ID: 1e0e1bce883f672ebace868dbf36e508b0bd0a203cabd13d5e28f922 Worker IP address: 172.28.0.2 Worker port: 38729 Worker PID: 1080\n","\u001b[2m\u001b[36m(TorchRunner pid=1080)\u001b[0m /usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:907: UserWarning: Using a target size (torch.Size([29, 1])) that is different to the input size (torch.Size([29, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n","\u001b[2m\u001b[36m(TorchRunner pid=1080)\u001b[0m   return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"]}]}]}