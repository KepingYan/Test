{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"raytrain_nyctaxi.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1-5XUDsPtQB8uaXJSrEDI38sYBahG2Rgk","authorship_tag":"ABX9TyOFN6/LkX1zMWKOQ/fd4zWM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **How RayDP works together with Ray**"],"metadata":{"id":"pJGi7Gb-DIRB"}},{"cell_type":"markdown","source":["## 1. Colab enviroment Setup"],"metadata":{"id":"NxuZwK3IDr6i"}},{"cell_type":"code","source":["# Install ray and raydp\n","! pip install ray==1.9\n","! pip install raydp\n","! pip install --upgrade pip\n","! pip install raydp\n","! pip install ray[tune]\n","! pip install torch==1.8.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n","! pip list"],"metadata":{"id":"Z697GdNUDoDG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2. Import dependencies"],"metadata":{"id":"qKJGlfBxE-un"}},{"cell_type":"code","source":["import ray\n","from ray import tune\n","import ray.data\n","from ray import train\n","from ray.train import Trainer, TrainingCallback, get_dataset_shard\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import raydp\n","from raydp.utils import random_split\n","from typing import List, Dict\n","\n","import os\n","import argparse\n","\n","import numpy as np\n","import pandas as pd\n","\n","from os.path import dirname, realpath\n","\n","import numpy as np\n","from pyspark.sql.functions import hour, quarter, month, year, dayofweek, dayofmonth, weekofyear, col, lit, udf, abs as functions_abs"],"metadata":{"id":"s5wCs7bMFHqt","executionInfo":{"status":"ok","timestamp":1651808601588,"user_tz":-480,"elapsed":5,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":["## 3. Get the data file"],"metadata":{"id":"AnAgoZKuELE-"}},{"cell_type":"code","source":["\n","base_date = np.datetime64(\"2010-01-01 00:00:00\")\n","\n","# The size of data\n","N = 2000\n","\n","fare_amount = np.random.uniform(3.0, 50.0, size=N)\n","pick_long = np.random.uniform(-74.2, -73.8, size=N)\n","pick_lat = np.random.uniform(40.7, 40.8, size=N)\n","drop_long = np.random.uniform(-74.2, -73.8, size=N)\n","drop_lat = np.random.uniform(40.7, 40.8, size=N)\n","passenger_count = np.random.randint(1, 5, size=N)\n","date = np.random.randint(0, 157680000, size=N) + base_date\n","date = np.array([t.item().strftime(\"%Y-%m-%d %H:%m:%S UTC\") for t in date])\n","key = [\"fake_key\"] * N\n","df = pd.DataFrame({\n","    \"key\": key,\n","    \"fare_amount\":fare_amount,\n","    \"pickup_datetime\": date,\n","    \"pickup_longitude\": pick_long,\n","    \"pickup_latitude\": pick_lat,\n","    \"dropoff_longitude\": drop_long,\n","    \"dropoff_latitude\": drop_lat,\n","    \"passenger_count\": passenger_count\n","    })\n","df.to_csv(\"/content/fake_nyctaxi.csv\", index=False)"],"metadata":{"id":"UKxQzx2pEKGd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Define the data_process function"],"metadata":{"id":"yYUc524PVI2W"}},{"cell_type":"code","source":["def clean_up(data):\n","    data = data.filter(col(\"pickup_longitude\")<=-72) \\\n","            .filter(col(\"pickup_longitude\")>=-76) \\\n","            .filter(col(\"dropoff_longitude\")<=-72) \\\n","            .filter(col(\"dropoff_longitude\")>=-76) \\\n","            .filter(col(\"pickup_latitude\")<=42) \\\n","            .filter(col(\"pickup_latitude\")>=38) \\\n","            .filter(col(\"dropoff_latitude\")<=42) \\\n","            .filter(col(\"dropoff_latitude\")>=38) \\\n","            .filter(col(\"passenger_count\")<=6) \\\n","            .filter(col(\"passenger_count\")>=1) \\\n","            .filter(col(\"fare_amount\") > 0) \\\n","            .filter(col(\"fare_amount\") < 250) \\\n","            .filter(col(\"dropoff_longitude\") != col(\"pickup_longitude\")) \\\n","            .filter(col(\"dropoff_latitude\") != col(\"pickup_latitude\"))\n","    return data\n","\n","# Add time related features\n","def add_time_features(data):\n","    data = data.withColumn(\"day\", dayofmonth(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"hour_of_day\", hour(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"day_of_week\", dayofweek(col(\"pickup_datetime\"))-2)\n","    data = data.withColumn(\"week_of_year\", weekofyear(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"month_of_year\", month(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"quarter_of_year\", quarter(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"year\", year(col(\"pickup_datetime\")))\n","    @udf(\"int\")\n","    def night(hour, weekday):\n","        if ((16 <= hour <= 20) and (weekday < 5)):\n","            return int(1)\n","        else:\n","            return int(0)\n","\n","    @udf(\"int\")\n","    def late_night(hour):\n","        if ((hour <= 6) or (hour >= 20)):\n","            return int(1)\n","        else:\n","            return int(0)\n","    data = data.withColumn(\"night\", night(\"hour_of_day\", \"day_of_week\"))\n","    data = data.withColumn(\"late_night\", late_night(\"hour_of_day\"))\n","    return data\n","\n","def add_distance_features(data):\n","    @udf(\"float\")\n","    def manhattan(lat1, lon1, lat2, lon2):\n","        return float(np.abs(lat2 - lat1) + np.abs(lon2 - lon1))\n","    # Location of NYC downtown\n","    ny = (-74.0063889, 40.7141667)\n","    # Location of the three airport in NYC\n","    jfk = (-73.7822222222, 40.6441666667)\n","    ewr = (-74.175, 40.69)\n","    lgr = (-73.87, 40.77)\n","    # Features about the distance between pickup/dropoff and airport\n","    data = data.withColumn(\"abs_diff_longitude\", functions_abs(col(\n","        \"dropoff_longitude\")-col(\"pickup_longitude\"))) \\\n","               .withColumn(\"abs_diff_latitude\", functions_abs(col(\n","        \"dropoff_latitude\") - col(\"pickup_latitude\")))\n","    data = data.withColumn(\"manhattan\", col(\n","        \"abs_diff_latitude\")+col(\"abs_diff_longitude\"))\n","    data = data.withColumn(\"pickup_distance_jfk\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(jfk[0]), lit(jfk[1])))\n","    data = data.withColumn(\"dropoff_distance_jfk\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(jfk[0]), lit(jfk[1])))\n","    data = data.withColumn(\"pickup_distance_ewr\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(ewr[0]), lit(ewr[1])))\n","    data = data.withColumn(\"dropoff_distance_ewr\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(ewr[0]), lit(ewr[1])))\n","    data = data.withColumn(\"pickup_distance_lgr\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(lgr[0]), lit(lgr[1])))\n","    data = data.withColumn(\"dropoff_distance_lgr\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(lgr[0]), lit(lgr[1])))\n","    data = data.withColumn(\"pickup_distance_downtown\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(ny[0]), lit(ny[1])))\n","    data = data.withColumn(\"dropoff_distance_downtown\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(ny[0]), lit(ny[1])))\n","    return data\n","\n","def drop_col(data):\n","    data = data.drop(\"pickup_datetime\") \\\n","            .drop(\"pickup_longitude\") \\\n","            .drop(\"pickup_latitude\") \\\n","            .drop(\"dropoff_longitude\") \\\n","            .drop(\"dropoff_latitude\") \\\n","            .drop(\"passenger_count\") \\\n","            .drop(\"key\")\n","    return data\n","\n","def nyc_taxi_preprocess(data):\n","    data = clean_up(data)\n","    data = add_time_features(data)\n","    data = add_distance_features(data)\n","    return drop_col(data)"],"metadata":{"id":"Jk5b9MNwVNNk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5. Init or connect to a ray cluster"],"metadata":{"id":"fSD4v0zKEx7d"}},{"cell_type":"code","source":["# \n","# ray.init(address=\"auto\")\n","# \n","ray.init(num_cpus=6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kOXeU_qmE1uH","executionInfo":{"status":"ok","timestamp":1651808085923,"user_tz":-480,"elapsed":5564,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"6e9ef621-ea24-4a1b-9f17-37a7e6df9b15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-06 03:34:42,787\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'metrics_export_port': 62617,\n"," 'node_id': '2debd0aa31226f76ebe3dfaa8e38dc3bc389dea687b43737aff54701',\n"," 'node_ip_address': '172.28.0.2',\n"," 'object_store_address': '/tmp/ray/session_2022-05-06_03-34-39_827110_63/sockets/plasma_store',\n"," 'raylet_ip_address': '172.28.0.2',\n"," 'raylet_socket_name': '/tmp/ray/session_2022-05-06_03-34-39_827110_63/sockets/raylet',\n"," 'redis_address': '172.28.0.2:6379',\n"," 'session_dir': '/tmp/ray/session_2022-05-06_03-34-39_827110_63',\n"," 'webui_url': '127.0.0.1:8265'}"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["## 6. Get a spark session"],"metadata":{"id":"xyzXEJg7FVrg"}},{"cell_type":"code","source":["app_name = \"NYC Taxi Fare Prediction with RayDP\"\n","num_executors = 1\n","cores_per_executor = 1\n","memory_per_executor = \"500M\"\n","spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)"],"metadata":{"id":"R9YydfatFfuF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 7. Data processing"],"metadata":{"id":"ZPgzXrdUFtL4"}},{"cell_type":"code","source":["# Read data from file\n","data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n","        .option(\"inferSchema\", \"true\") \\\n","        .load(\"/content/fake_nyctaxi.csv\")\n","# Set spark timezone for processing datetime\n","spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n","# Transform the dataset\n","data = nyc_taxi_preprocess(data)\n","# Split data into train_dataset and test_dataset\n","train_df, test_df = random_split(data, [0.9, 0.1], 0)\n","features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n","# Convert spark dataframe into ray Dataset\n","# Remember to align ``parallelism`` with ``num_workers`` of ray train\n","train_dataset = ray.data.from_spark(train_df, parallelism = 8)\n","test_dataset = ray.data.from_spark(test_df, parallelism = 8)\n","feature_dtype = [torch.float] * len(features)"],"metadata":{"id":"ztuBpv9SF0_R","executionInfo":{"status":"ok","timestamp":1651808126170,"user_tz":-480,"elapsed":31269,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"48246b96-33f2-43d0-b036-8be297c57f78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n"]}]},{"cell_type":"markdown","source":["## 8. Define a neural network model"],"metadata":{"id":"9PujezwdGJ87"}},{"cell_type":"code","source":["class NYC_Model(nn.Module):\n","    def __init__(self, cols):\n","        super().__init__()\n","        self.fc1 = nn.Linear(cols, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 16)\n","        self.fc5 = nn.Linear(16, 1)\n","        self.bn1 = nn.BatchNorm1d(256)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.bn4 = nn.BatchNorm1d(16)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = self.bn1(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.bn2(x)\n","        x = F.relu(self.fc3(x))\n","        x = self.bn3(x)\n","        x = F.relu(self.fc4(x))\n","        x = self.bn4(x)\n","        x = self.fc5(x)\n","        return x"],"metadata":{"id":"RcsoN3tWGUEM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 9. Define train and test function"],"metadata":{"id":"DZ81HRrOGVVj"}},{"cell_type":"code","source":["def train_epoch(dataset, model, criterion, optimizer):\n","    model.train()\n","    train_loss, correct, data_size, batch_idx = 0, 0, 0, 0\n","    for batch_idx, (inputs, targets) in enumerate(dataset):\n","        # Compute prediction error\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        train_loss += loss.item()\n","        correct += (outputs == targets).sum().item()\n","        data_size += inputs.size(0)\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    train_loss /= (batch_idx + 1)\n","    train_acc = correct/data_size\n","    return train_acc, train_loss\n","\n","def test_epoch(dataset, model, criterion):\n","    model.eval()\n","    test_loss, correct, data_size, batch_idx = 0, 0, 0, 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(dataset):\n","            # Compute prediction error\n","            outputs = model(inputs)\n","            test_loss += criterion(outputs, targets).item()\n","            correct += (outputs == targets).sum().item()\n","            data_size += inputs.size(0)\n","    test_loss /= (batch_idx + 1)\n","    test_acc = correct/data_size\n","    return test_acc, test_loss"],"metadata":{"id":"0Y_08OhMGd4a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10. Define train function"],"metadata":{"id":"dRAamyi3GewE"}},{"cell_type":"code","source":["def train_func(config):\n","    num_epochs = config[\"num_epochs\"]\n","    lr = config[\"lr\"]\n","    batch_size = config[\"batch_size\"]\n","    # Then convert to torch datasets\n","    train_data_shard = get_dataset_shard(\"train\")\n","    train_dataset = train_data_shard.to_torch(feature_columns=features,\n","                                              label_column=\"fare_amount\",\n","                                              label_column_dtype=torch.float,\n","                                              feature_column_dtypes=feature_dtype,\n","                                              batch_size=batch_size)\n","    test_data_shard = get_dataset_shard(\"test\")\n","    test_dataset = test_data_shard.to_torch(feature_columns=features,\n","                                            label_column=\"fare_amount\",\n","                                            label_column_dtype=torch.float,\n","                                            feature_column_dtypes=feature_dtype,\n","                                            batch_size=batch_size)\n","    model = NYC_Model(len(features))\n","    model = train.torch.prepare_model(model)\n","    criterion = nn.SmoothL1Loss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    loss_results = []\n","    for epoch in range(num_epochs):\n","        train_acc, train_loss = train_epoch(train_dataset, model, criterion, optimizer)\n","        test_acc, test_loss = test_epoch(test_dataset, model, criterion)\n","        train.report(epoch = epoch, train_acc = train_acc, train_loss = train_loss)\n","        train.report(epoch = epoch, test_acc=test_acc, test_loss=test_loss)\n","        loss_results.append(test_loss)"],"metadata":{"id":"76x_ZEdKGmd3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 11. Define the callback function"],"metadata":{"id":"d-wfpCJ_NL4-"}},{"cell_type":"code","source":["class PrintingCallback(TrainingCallback):\n","    def handle_result(self, results: List[Dict], **info):\n","        print(results)"],"metadata":{"id":"omYjJ7WTNZUo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 12. Train model via ray train"],"metadata":{"id":"kaW_aC5zGoWZ"}},{"cell_type":"code","source":["trainer = Trainer(backend=\"torch\", num_workers=num_executors)\n","trainer.start()\n","results = trainer.run(\n","    train_func, config={\"num_epochs\": 10, \"lr\": 0.1, \"batch_size\": 8},\n","    callbacks=[PrintingCallback()],\n","    dataset={\n","        \"train\": train_dataset,\n","        \"test\": test_dataset\n","    }\n",")\n","trainer.shutdown()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rerm_OwoG0g9","executionInfo":{"status":"ok","timestamp":1651808154964,"user_tz":-480,"elapsed":28877,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"outputId":"a3cc68c3-2e11-490a-c6a0-5e092b600182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-06 03:35:25,648\tINFO trainer.py:172 -- Trainer logs will be logged in: /root/ray_results/train_2022-05-06_03-35-25\n","2022-05-06 03:35:27,366\tINFO trainer.py:178 -- Run results will be logged in: /root/ray_results/train_2022-05-06_03-35-25/run_001\n","\u001b[2m\u001b[36m(BaseWorkerMixin pid=2470)\u001b[0m 2022-05-06 03:35:27,363\tINFO torch.py:67 -- Setting up process group for: env:// [rank=0, world_size=1]\n","\u001b[2m\u001b[36m(BaseWorkerMixin pid=2470)\u001b[0m 2022-05-06 03:35:27,453\tINFO torch.py:239 -- Moving model to device: cpu\n"]},{"output_type":"stream","name":"stdout","text":["[{'epoch': 0, 'train_acc': 0.0, 'train_loss': 12.028679358107704, '_timestamp': 1651808130, '_time_this_iter_s': 2.573432445526123, '_training_iteration': 1}]\n","[{'epoch': 0, 'test_acc': 0.0, 'test_loss': 678.7765073423033, '_timestamp': 1651808130, '_time_this_iter_s': 0.0010333061218261719, '_training_iteration': 2}]\n","[{'epoch': 1, 'train_acc': 0.0, 'train_loss': 11.546148598194122, '_timestamp': 1651808133, '_time_this_iter_s': 3.356105089187622, '_training_iteration': 3}]\n","[{'epoch': 1, 'test_acc': 0.0, 'test_loss': 11.001856521323875, '_timestamp': 1651808133, '_time_this_iter_s': 0.0009887218475341797, '_training_iteration': 4}]\n","[{'epoch': 2, 'train_acc': 0.0, 'train_loss': 11.407406462090355, '_timestamp': 1651808135, '_time_this_iter_s': 2.6061911582946777, '_training_iteration': 5}]\n","[{'epoch': 2, 'test_acc': 0.0, 'test_loss': 10.934884194974545, '_timestamp': 1651808135, '_time_this_iter_s': 0.0008146762847900391, '_training_iteration': 6}]\n","[{'epoch': 3, 'train_acc': 0.0, 'train_loss': 11.4163396188191, '_timestamp': 1651808138, '_time_this_iter_s': 2.7803711891174316, '_training_iteration': 7}]\n","[{'epoch': 3, 'test_acc': 0.0, 'test_loss': 10.800589932335747, '_timestamp': 1651808138, '_time_this_iter_s': 0.003685474395751953, '_training_iteration': 8}]\n","[{'epoch': 4, 'train_acc': 0.0, 'train_loss': 11.362313683543887, '_timestamp': 1651808141, '_time_this_iter_s': 2.6243724822998047, '_training_iteration': 9}]\n","[{'epoch': 4, 'test_acc': 0.0, 'test_loss': 10.672738552093506, '_timestamp': 1651808141, '_time_this_iter_s': 0.0008246898651123047, '_training_iteration': 10}]\n","[{'epoch': 5, 'train_acc': 0.0, 'train_loss': 11.307107365557126, '_timestamp': 1651808143, '_time_this_iter_s': 2.5807156562805176, '_training_iteration': 11}]\n","[{'epoch': 5, 'test_acc': 0.0, 'test_loss': 19.247474952980323, '_timestamp': 1651808143, '_time_this_iter_s': 0.0007758140563964844, '_training_iteration': 12}]\n","[{'epoch': 6, 'train_acc': 0.0, 'train_loss': 11.254692724772863, '_timestamp': 1651808146, '_time_this_iter_s': 2.497166633605957, '_training_iteration': 13}]\n","[{'epoch': 6, 'test_acc': 0.0, 'test_loss': 10.760192058704517, '_timestamp': 1651808146, '_time_this_iter_s': 0.0008311271667480469, '_training_iteration': 14}]\n","[{'epoch': 7, 'train_acc': 0.0, 'train_loss': 11.262931608728, '_timestamp': 1651808149, '_time_this_iter_s': 2.6468493938446045, '_training_iteration': 15}]\n","[{'epoch': 7, 'test_acc': 0.0, 'test_loss': 16.720597161187065, '_timestamp': 1651808149, '_time_this_iter_s': 0.00077056884765625, '_training_iteration': 16}]\n","[{'epoch': 8, 'train_acc': 0.0, 'train_loss': 11.285495562212807, '_timestamp': 1651808151, '_time_this_iter_s': 2.5958564281463623, '_training_iteration': 17}]\n","[{'epoch': 8, 'test_acc': 0.0, 'test_loss': 10.67799154917399, '_timestamp': 1651808151, '_time_this_iter_s': 0.0008313655853271484, '_training_iteration': 18}]\n","[{'epoch': 9, 'train_acc': 0.0, 'train_loss': 11.243393444589206, '_timestamp': 1651808154, '_time_this_iter_s': 2.6093428134918213, '_training_iteration': 19}]\n","[{'epoch': 9, 'test_acc': 0.0, 'test_loss': 202223.33506944444, '_timestamp': 1651808154, '_time_this_iter_s': 0.000989675521850586, '_training_iteration': 20}]\n"]}]},{"cell_type":"markdown","source":["## 13. shut down ray and raydp"],"metadata":{"id":"MnUdAC7FG5HT"}},{"cell_type":"code","source":["raydp.stop_spark()\n","ray.shutdown()"],"metadata":{"id":"riDLFnZDG8Hr"},"execution_count":null,"outputs":[]}]}