{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"raysgd_nyctaxi.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPix9Wd62ZCGuhvHAJ440p3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **How RayDP works together with Ray**"],"metadata":{"id":"qjIgDCbCZk9e"}},{"cell_type":"markdown","source":["## 1. Colab enviroment Setup"],"metadata":{"id":"3CtW-2NBZrKz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hfnvVS0cZMh6"},"outputs":[],"source":["# Install ray and raydp\n","! pip install ray==1.9\n","! pip install raydp\n","! pip install --upgrade pip\n","! pip install raydp\n","! pip install ray[tune]\n","! pip install torch==1.8.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n","! pip list"]},{"cell_type":"markdown","source":["## 2. Import dependencies"],"metadata":{"id":"Oci4dxu8Z2Z5"}},{"cell_type":"code","source":["import ray\n","from ray.util.sgd.torch import TrainingOperator\n","from ray.util.sgd import TorchTrainer\n","from ray import tune\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data.dataloader import DataLoader\n","\n","import raydp\n","from raydp.torch import TorchEstimator\n","from raydp.utils import random_split\n","from raydp.spark import RayMLDataset\n","\n","import os\n","import argparse\n","\n","import numpy as np\n","import pandas as pd\n","\n","from os.path import dirname, realpath\n","\n","import numpy as np\n","from pyspark.sql.functions import hour, quarter, month, year, dayofweek, dayofmonth, weekofyear, col, lit, udf, abs as functions_abs"],"metadata":{"id":"gOrQr52wZ6Pv","executionInfo":{"status":"ok","timestamp":1651810165098,"user_tz":-480,"elapsed":9,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## 3. Get the data file"],"metadata":{"id":"zudSNBh-Zuba"}},{"cell_type":"code","source":["\n","base_date = np.datetime64(\"2010-01-01 00:00:00\")\n","\n","# The size of data\n","N = 2000\n","\n","fare_amount = np.random.uniform(3.0, 50.0, size=N)\n","pick_long = np.random.uniform(-74.2, -73.8, size=N)\n","pick_lat = np.random.uniform(40.7, 40.8, size=N)\n","drop_long = np.random.uniform(-74.2, -73.8, size=N)\n","drop_lat = np.random.uniform(40.7, 40.8, size=N)\n","passenger_count = np.random.randint(1, 5, size=N)\n","date = np.random.randint(0, 157680000, size=N) + base_date\n","date = np.array([t.item().strftime(\"%Y-%m-%d %H:%m:%S UTC\") for t in date])\n","key = [\"fake_key\"] * N\n","df = pd.DataFrame({\n","    \"key\": key,\n","    \"fare_amount\":fare_amount,\n","    \"pickup_datetime\": date,\n","    \"pickup_longitude\": pick_long,\n","    \"pickup_latitude\": pick_lat,\n","    \"dropoff_longitude\": drop_long,\n","    \"dropoff_latitude\": drop_lat,\n","    \"passenger_count\": passenger_count\n","    })\n","df.to_csv(\"/content/fake_nyctaxi.csv\", index=False)"],"metadata":{"id":"wQWcDItGZz92","executionInfo":{"status":"ok","timestamp":1651810165098,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## 4. Define the data_process function"],"metadata":{"id":"P0ZMuvRBfbMh"}},{"cell_type":"code","source":["def clean_up(data):\n","    data = data.filter(col(\"pickup_longitude\")<=-72) \\\n","            .filter(col(\"pickup_longitude\")>=-76) \\\n","            .filter(col(\"dropoff_longitude\")<=-72) \\\n","            .filter(col(\"dropoff_longitude\")>=-76) \\\n","            .filter(col(\"pickup_latitude\")<=42) \\\n","            .filter(col(\"pickup_latitude\")>=38) \\\n","            .filter(col(\"dropoff_latitude\")<=42) \\\n","            .filter(col(\"dropoff_latitude\")>=38) \\\n","            .filter(col(\"passenger_count\")<=6) \\\n","            .filter(col(\"passenger_count\")>=1) \\\n","            .filter(col(\"fare_amount\") > 0) \\\n","            .filter(col(\"fare_amount\") < 250) \\\n","            .filter(col(\"dropoff_longitude\") != col(\"pickup_longitude\")) \\\n","            .filter(col(\"dropoff_latitude\") != col(\"pickup_latitude\"))\n","    return data\n","\n","# Add time related features\n","def add_time_features(data):\n","    data = data.withColumn(\"day\", dayofmonth(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"hour_of_day\", hour(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"day_of_week\", dayofweek(col(\"pickup_datetime\"))-2)\n","    data = data.withColumn(\"week_of_year\", weekofyear(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"month_of_year\", month(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"quarter_of_year\", quarter(col(\"pickup_datetime\")))\n","    data = data.withColumn(\"year\", year(col(\"pickup_datetime\")))\n","    @udf(\"int\")\n","    def night(hour, weekday):\n","        if ((16 <= hour <= 20) and (weekday < 5)):\n","            return int(1)\n","        else:\n","            return int(0)\n","\n","    @udf(\"int\")\n","    def late_night(hour):\n","        if ((hour <= 6) or (hour >= 20)):\n","            return int(1)\n","        else:\n","            return int(0)\n","    data = data.withColumn(\"night\", night(\"hour_of_day\", \"day_of_week\"))\n","    data = data.withColumn(\"late_night\", late_night(\"hour_of_day\"))\n","    return data\n","\n","def add_distance_features(data):\n","    @udf(\"float\")\n","    def manhattan(lat1, lon1, lat2, lon2):\n","        return float(np.abs(lat2 - lat1) + np.abs(lon2 - lon1))\n","    # Location of NYC downtown\n","    ny = (-74.0063889, 40.7141667)\n","    # Location of the three airport in NYC\n","    jfk = (-73.7822222222, 40.6441666667)\n","    ewr = (-74.175, 40.69)\n","    lgr = (-73.87, 40.77)\n","    # Features about the distance between pickup/dropoff and airport\n","    data = data.withColumn(\"abs_diff_longitude\", functions_abs(col(\n","        \"dropoff_longitude\")-col(\"pickup_longitude\"))) \\\n","               .withColumn(\"abs_diff_latitude\", functions_abs(col(\n","        \"dropoff_latitude\") - col(\"pickup_latitude\")))\n","    data = data.withColumn(\"manhattan\", col(\n","        \"abs_diff_latitude\")+col(\"abs_diff_longitude\"))\n","    data = data.withColumn(\"pickup_distance_jfk\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(jfk[0]), lit(jfk[1])))\n","    data = data.withColumn(\"dropoff_distance_jfk\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(jfk[0]), lit(jfk[1])))\n","    data = data.withColumn(\"pickup_distance_ewr\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(ewr[0]), lit(ewr[1])))\n","    data = data.withColumn(\"dropoff_distance_ewr\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(ewr[0]), lit(ewr[1])))\n","    data = data.withColumn(\"pickup_distance_lgr\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(lgr[0]), lit(lgr[1])))\n","    data = data.withColumn(\"dropoff_distance_lgr\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(lgr[0]), lit(lgr[1])))\n","    data = data.withColumn(\"pickup_distance_downtown\", manhattan(\n","        \"pickup_longitude\", \"pickup_latitude\", lit(ny[0]), lit(ny[1])))\n","    data = data.withColumn(\"dropoff_distance_downtown\", manhattan(\n","        \"dropoff_longitude\", \"dropoff_latitude\", lit(ny[0]), lit(ny[1])))\n","    return data\n","\n","def drop_col(data):\n","    data = data.drop(\"pickup_datetime\") \\\n","            .drop(\"pickup_longitude\") \\\n","            .drop(\"pickup_latitude\") \\\n","            .drop(\"dropoff_longitude\") \\\n","            .drop(\"dropoff_latitude\") \\\n","            .drop(\"passenger_count\") \\\n","            .drop(\"key\")\n","    return data\n","\n","def nyc_taxi_preprocess(data):\n","    data = clean_up(data)\n","    data = add_time_features(data)\n","    data = add_distance_features(data)\n","    return drop_col(data)"],"metadata":{"id":"R98pdMicfeWW","executionInfo":{"status":"ok","timestamp":1651810165099,"user_tz":-480,"elapsed":8,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["## 5. Init or connect to a ray cluster"],"metadata":{"id":"GsMWgDzsaKQ-"}},{"cell_type":"code","source":["# \n","# ray.init(address=\"auto\")\n","# \n","ray.init(num_cpus=6)"],"metadata":{"id":"JUGF-DC4aPsg","executionInfo":{"status":"ok","timestamp":1651810169832,"user_tz":-480,"elapsed":4741,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"434f7a45-c947-40f5-ce88-70dffc903a72"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["2022-05-06 04:09:27,083\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"]},{"output_type":"execute_result","data":{"text/plain":["{'metrics_export_port': 59568,\n"," 'node_id': 'bac610b2509573b1935eadbffd5d63cbe3e7b255b5ed3834a8dc5a41',\n"," 'node_ip_address': '172.28.0.2',\n"," 'object_store_address': '/tmp/ray/session_2022-05-06_04-09-24_557903_60/sockets/plasma_store',\n"," 'raylet_ip_address': '172.28.0.2',\n"," 'raylet_socket_name': '/tmp/ray/session_2022-05-06_04-09-24_557903_60/sockets/raylet',\n"," 'redis_address': '172.28.0.2:6379',\n"," 'session_dir': '/tmp/ray/session_2022-05-06_04-09-24_557903_60',\n"," 'webui_url': '127.0.0.1:8265'}"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## 6. Get a spark session"],"metadata":{"id":"5o3eGDJFaTPq"}},{"cell_type":"code","source":["app_name = \"NYC Taxi Fare Prediction with RayDP\"\n","num_executors = 1\n","cores_per_executor = 1\n","memory_per_executor = \"500M\"\n","spark = raydp.init_spark(app_name, num_executors, cores_per_executor, memory_per_executor)"],"metadata":{"id":"PtIx9ZM6aXNL","executionInfo":{"status":"ok","timestamp":1651810175921,"user_tz":-480,"elapsed":6102,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## 7. Data processing"],"metadata":{"id":"Fc0fk3cqadZo"}},{"cell_type":"code","source":["# Read data from file\n","data = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n","        .option(\"inferSchema\", \"true\") \\\n","        .load('/content/fake_nyctaxi.csv')\n","# Set spark timezone for processing datetime\n","spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n","# Transform the dataset\n","data = nyc_taxi_preprocess(data)\n","# Split data into train_dataset and test_dataset\n","train_df, test_df = random_split(data, [0.9, 0.1], 0)\n","features = [field.name for field in list(train_df.schema) if field.name != \"fare_amount\"]\n","# Convert spark dataframe into ML Dataset\n","train_dataset = RayMLDataset.from_spark(train_df, num_executors, 32)\n","test_dataset = RayMLDataset.from_spark(test_df, num_executors, 32)\n","# Then convert to torch datasets\n","train_dataset = train_dataset.to_torch(feature_columns=features, label_column=\"fare_amount\")\n","test_dataset = test_dataset.to_torch(feature_columns=features, label_column=\"fare_amount\")"],"metadata":{"id":"NBKBM2aNaeHa","executionInfo":{"status":"ok","timestamp":1651810212043,"user_tz":-480,"elapsed":36140,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"008620bf-762f-4caf-9b64-845830ee3801"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: An illegal reflective access operation has occurred\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/lib/python3.7/dist-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n","\u001b[2m\u001b[33m(raylet)\u001b[0m WARNING: All illegal access operations will be denied in a future release\n"]}]},{"cell_type":"markdown","source":["## 8. Define a neural network model"],"metadata":{"id":"QAVSjJJ5awAl"}},{"cell_type":"code","source":["class NYC_Model(nn.Module):\n","    def __init__(self, cols):\n","        super(NYC_Model, self).__init__()\n","        \n","        self.fc1 = nn.Linear(cols, 256)\n","        self.fc2 = nn.Linear(256, 128)\n","        self.fc3 = nn.Linear(128, 64)\n","        self.fc4 = nn.Linear(64, 16)\n","        self.fc5 = nn.Linear(16, 1)\n","        \n","        self.bn1 = nn.BatchNorm1d(256)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(64)\n","        self.bn4 = nn.BatchNorm1d(16)\n","\n","    def forward(self, *x):\n","        x = torch.cat(x, dim=1)\n","        x = F.relu(self.fc1(x))\n","        x = self.bn1(x)\n","        x = F.relu(self.fc2(x))\n","        x = self.bn2(x)\n","        x = F.relu(self.fc3(x))\n","        x = self.bn3(x)\n","        x = F.relu(self.fc4(x))\n","        x = self.bn4(x)\n","        x = self.fc5(x)\n","        \n","        return x"],"metadata":{"id":"K3W2bLraawuZ","executionInfo":{"status":"ok","timestamp":1651810212045,"user_tz":-480,"elapsed":21,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["## 9. Define the TrainingOperator"],"metadata":{"id":"Mpg5LsKQa0Wg"}},{"cell_type":"code","source":["class CustomOperator(TrainingOperator):\n","    def setup(self, config):\n","        nyc_model = NYC_Model(len(features))\n","        criterion = nn.SmoothL1Loss()\n","        optimizer = torch.optim.Adam(nyc_model.parameters(), lr=config['lr'])\n","        # A quick work-around for https://github.com/ray-project/ray/issues/14352\n","        self.model, self.optimizer, self.criterion = self.register(\n","            models=[nyc_model], optimizers=[optimizer], criterion=criterion)\n","        self.model = self.model[0]\n","        self.optimizer = self.optimizer[0]\n","        # Get the corresponging shard\n","        train_shard = train_dataset.get_shard(self.world_rank)\n","        train_loader = DataLoader(train_shard, batch_size=64)\n","        test_shard = test_dataset.get_shard(self.world_rank)\n","        val_loader = DataLoader(test_shard, batch_size=64)\n","        self.register_data(train_loader=train_loader, validation_loader=val_loader)"],"metadata":{"id":"3474TwAObDER","executionInfo":{"status":"ok","timestamp":1651810212046,"user_tz":-480,"elapsed":21,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## 10. Train model via TorchTrainer"],"metadata":{"id":"baF_IhgYbFnk"}},{"cell_type":"code","source":["trainer = TorchTrainer(training_operator_cls=CustomOperator,\n","                       num_workers=num_executors,\n","                       add_dist_sampler=False,\n","                       num_cpus_per_worker=1,\n","                       config={\"lr\":0.01})\n","for i in range(10):\n","    stats = trainer.train()\n","    print(stats)\n","    val_stats = trainer.validate()\n","    print(val_stats)\n","trainer.shutdown()"],"metadata":{"id":"VueNV1HzbOOG","executionInfo":{"status":"ok","timestamp":1651810217246,"user_tz":-480,"elapsed":5221,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"795b1701-c44a-4584-bbe4-dfc773a0ad5f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[2m\u001b[36m(TorchRunner pid=1683)\u001b[0m /usr/local/lib/python3.7/dist-packages/ray/util/sgd/torch/torch_dataset.py:35: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","\u001b[2m\u001b[36m(TorchRunner pid=1683)\u001b[0m   t = torch.as_tensor(column, dtype=dtype)\n"]},{"output_type":"stream","name":"stdout","text":["{'num_samples': 1789, 'epoch': 1.0, 'batch_count': 28.0, 'train_loss': 24.79593428371338, 'last_train_loss': 22.45583724975586}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 39.25195845834452, 'last_val_loss': 40.1341438293457, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 2.0, 'batch_count': 28.0, 'train_loss': 20.867513675806975, 'last_train_loss': 16.393869400024414}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 19.96777047252203, 'last_val_loss': 20.588455200195312, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 3.0, 'batch_count': 28.0, 'train_loss': 14.817819767520707, 'last_train_loss': 14.141854286193848}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 13.604915072002681, 'last_val_loss': 12.041680335998535, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 4.0, 'batch_count': 28.0, 'train_loss': 11.712579469163702, 'last_train_loss': 12.467962265014648}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 20.672127863807138, 'last_val_loss': 18.82508659362793, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 5.0, 'batch_count': 28.0, 'train_loss': 11.33270683842974, 'last_train_loss': 11.898149490356445}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 10.439362426504704, 'last_val_loss': 11.358839988708496, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 6.0, 'batch_count': 28.0, 'train_loss': 11.315674635203209, 'last_train_loss': 9.52433967590332}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 10.90775784045034, 'last_val_loss': 9.501238822937012, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 7.0, 'batch_count': 28.0, 'train_loss': 11.339813465909494, 'last_train_loss': 12.15388298034668}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 11.34981132344612, 'last_val_loss': 9.756518363952637, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 8.0, 'batch_count': 28.0, 'train_loss': 11.274469528070304, 'last_train_loss': 12.578353881835938}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 27.60400330963858, 'last_val_loss': 27.966083526611328, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 9.0, 'batch_count': 28.0, 'train_loss': 11.310191474326034, 'last_train_loss': 11.5827054977417}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 10.532964927890289, 'last_val_loss': 9.990525245666504, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n","{'num_samples': 1789, 'epoch': 10.0, 'batch_count': 28.0, 'train_loss': 11.275519651431088, 'last_train_loss': 10.656170845031738}\n","{'num_samples': 211, 'batch_count': 4.0, 'val_loss': 10.649554049234254, 'last_val_loss': 8.333271026611328, 'val_accuracy': 0.0, 'last_val_accuracy': 0.0}\n"]}]},{"cell_type":"markdown","source":["## 11. shut down ray and raydp"],"metadata":{"id":"v7P5dx2ZbS0I"}},{"cell_type":"code","source":["raydp.stop_spark()\n","ray.shutdown()"],"metadata":{"id":"QJCqPcT6bU3v","executionInfo":{"status":"ok","timestamp":1651810219558,"user_tz":-480,"elapsed":2315,"user":{"displayName":"Ke Yan","userId":"12157985255311286389"}}},"execution_count":26,"outputs":[]}]}